{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework (Week 3) -- Biometrics (20 points)\n",
    "\n",
    "In this homework we train Biometrics Verification model and use some features to increase quality:\n",
    "1) Train ECAPA-TDNN (10 points)\n",
    "2) Any contrastive loss (10 points)\n",
    "\n",
    "Link to download dataset: https://disk.yandex.ru/d/lyhtieYbxQOYqw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import requests\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as torch_data\n",
    "import torchaudio\n",
    "import tqdm.notebook as tqdm\n",
    "import urllib\n",
    "\n",
    "import dataset\n",
    "\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# %matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 0\n",
    "\n",
    "np.random.seed(SEED) \n",
    "torch.manual_seed(SEED) \n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_url = 'https://cloud-api.yandex.net/v1/disk/public/resources/download?'\n",
    "# public_key = 'https://disk.yandex.ru/d/lyhtieYbxQOYqw'\n",
    "# final_url = base_url + urllib.parse.urlencode(dict(public_key=public_key))\n",
    "# response = requests.get(final_url)\n",
    "# download_url = response.json()['href']\n",
    "# !wget -O voxceleb.tar.gz \"{download_url}\" --no-check-certificate \n",
    "# !tar -xf voxceleb.tar.gz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some model train example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'\n",
    "DATADIR = 'voxceleb'\n",
    "FEATS = 80\n",
    "LOADER_WORKERS = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torchaudio\\functional\\functional.py:584: UserWarning: At least one mel filterbank has all zero values. The value for `n_mels` (128) may be set too high. Or, the value for `n_freqs` (201) may be set too low.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "transform = torchaudio.transforms.MFCC(\n",
    "    n_mfcc=FEATS\n",
    ") # You can try some other transformations here\n",
    "trainset = dataset.Dataset(os.path.join(DATADIR, 'voxceleb_train'), transform)\n",
    "testset = dataset.Dataset(os.path.join(DATADIR, 'voxceleb_test'), transform)\n",
    "test_targets = pd.read_csv(os.path.join(DATADIR, 'target.csv')).values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16000"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "transform.MelSpectrogram.sample_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "window length     : 25.0 [ms]\n",
      "window hop length : 12.5 [ms]\n"
     ]
    }
   ],
   "source": [
    "print(f\"window length     : {transform.MelSpectrogram.win_length/transform.MelSpectrogram.sample_rate*1000} [ms]\\n\"\n",
    "      f\"window hop length : {transform.MelSpectrogram.hop_length/transform.MelSpectrogram.sample_rate*1000} [ms]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, input_shape: int, output_shape: int, hidden: int, kernel: int = 7, sride: int = 2):\n",
    "        super().__init__()\n",
    "        self._emb = nn.Sequential(\n",
    "            nn.Conv1d(input_shape, hidden, kernel, stride=sride),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden, hidden, kernel, stride=sride),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv1d(hidden, hidden, kernel, stride=sride),\n",
    "            nn.AdaptiveMaxPool1d(1),\n",
    "        )\n",
    "        self._final = nn.Sequential(\n",
    "            nn.Linear(hidden, output_shape),\n",
    "            nn.LogSoftmax(dim=-1)\n",
    "        )\n",
    "\n",
    "    def forward(self, X) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        emb = self._emb(X).squeeze(2)\n",
    "        return self._final(emb), emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics\n",
    "\n",
    "Cosine similarity:\n",
    "$CS(a, b) = \\frac{<a, b>}{\\|a\\| \\|b\\|}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(a, b):\n",
    "    a = a.reshape(-1)\n",
    "    b = b.reshape(-1)\n",
    "    return np.dot(a, b) / (np.linalg.norm(a) * np.linalg.norm(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is O(N log N) algorithm for find best_eer:\n",
    "1) Sort prediction by probability\n",
    "2) Going through items and recalculating far and frr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "def best_eer(data):\n",
    "    full = sorted(data, key=lambda x: (x[0], -x[1]))\n",
    "    pos = len([item for item in full if item[1] == 1])\n",
    "    neg = len(full) - pos\n",
    "    cur_pos = pos\n",
    "    cur_neg = 0\n",
    "    best_eer = 1\n",
    "    for _, label in full:\n",
    "        if label == 1:\n",
    "            cur_pos -= 1\n",
    "        else:\n",
    "            cur_neg += 1\n",
    "        cur_eer = max((pos - cur_pos) / pos, (neg - cur_neg) / neg)\n",
    "        best_eer = min(best_eer, cur_eer)\n",
    "    return best_eer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_stage(model, opt, batch_size: int = 256):\n",
    "    loader = torch_data.DataLoader(\n",
    "        trainset,\n",
    "        shuffle=True,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=dataset.collate_fn,\n",
    "        num_workers=LOADER_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    loss_sum = 0.0\n",
    "    batches = 0\n",
    "    for X, Y, _ in tqdm.tqdm(loader):\n",
    "        logits, _ = model.forward(X.to(DEVICE))\n",
    "        loss = F.nll_loss(logits, Y.to(DEVICE))\n",
    "        loss_sum += loss.item()\n",
    "        batches += 1\n",
    "        opt.zero_grad()\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "    return loss_sum / batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = torch_data.DataLoader(\n",
    "    testset,\n",
    "    batch_size=1,\n",
    "    collate_fn=dataset.collate_fn,\n",
    "    num_workers=1,\n",
    "    pin_memory=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_eval_score(model: nn.Module, batch_size: int = 256):\n",
    "    loader = torch_data.DataLoader(\n",
    "        testset,\n",
    "        batch_size=batch_size,\n",
    "        collate_fn=dataset.collate_fn,\n",
    "        num_workers=LOADER_WORKERS,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    items = {}\n",
    "    target_scores = []\n",
    "    with torch.no_grad():\n",
    "        for X, _, pathes in tqdm.tqdm(loader):\n",
    "            _, embds = model.forward(X.to(DEVICE))\n",
    "            embds = embds.cpu().data.numpy().reshape(X.shape[0], -1)\n",
    "            for embd, path in zip(embds, pathes):\n",
    "                items[path] = embd\n",
    "    for item1, item2, target in test_targets:\n",
    "        target_scores.append((cosine_similarity(items[item1], items[item2]), target))\n",
    "    return best_eer(target_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(\n",
    "    model: nn.Module,\n",
    "    opt,\n",
    "    batch_size: int = 256,\n",
    "    epochs: int = 10,\n",
    "    train_fun = train_stage,\n",
    "    train_kwargs = {},\n",
    ") -> None:  \n",
    "    train_losses = []\n",
    "    eval_scores = []\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        train_losses.append(train_fun(model, opt, batch_size=batch_size))\n",
    "        model.eval()\n",
    "        eval_scores.append(calc_eval_score(model, batch_size=batch_size))\n",
    "        clear_output()\n",
    "        fig, axis = plt.subplots(1, 2, figsize=(15, 7))\n",
    "        axis[0].plot(np.arange(1, epoch + 2), train_losses, label='train CE loss')\n",
    "        axis[1].plot(np.arange(1, epoch + 2), eval_scores, label='eval')\n",
    "        axis[0].set(xlabel='epoch', ylabel='CE Loss')\n",
    "        axis[1].set(xlabel='epoch', ylabel='EER')\n",
    "        fig.legend()\n",
    "        plt.show()\n",
    "        \n",
    "        torch.save(model.state_dict(), f'model_{epoch}')\n",
    "        torch.save(opt.state_dict(), f'opt_{epoch}')\n",
    "        \n",
    "        print(f'Epoch {epoch + 1}. Train loss {train_losses[-1]}. Eval score {eval_scores[-1]}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(FEATS, trainset.speakers(), hidden=128).to(DEVICE)\n",
    "opt = optim.Adam(model.parameters())\n",
    "train(model, opt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ECAPA TDNN (10 points)\n",
    "\n",
    "Paper: https://arxiv.org/pdf/2005.07143.pdf\n",
    "\n",
    "Papers for ECAPA parts:\n",
    "- SE-Blocks - https://arxiv.org/pdf/1709.01507.pdf\n",
    "- Res2Net - https://arxiv.org/pdf/1904.01169.pdf\n",
    "- Attentive Stats Pooling - https://arxiv.org/pdf/1803.10963.pdf\n",
    "- AAM Softmax - https://arxiv.org/pdf/1906.07317.pdf\n",
    "\n",
    "Also you can optionally add other settings for paper:\n",
    "- SpecAug\n",
    "- Weight decay for optimizer\n",
    "- LR scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: In some class templates, the `__call__` method was used. However, this is a mistake. When inheriting from `nn.Module`, you should almost always override the `forward` method to ensure expected behavior. Defining `__call__` directly can cause issues, such as hooks not being tracked if they were created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SEBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_channels: int, \n",
    "        reduction: int\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        self.squeeze = nn.AdaptiveAvgPool1d(output_size=1)\n",
    "        self.excitation = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=input_channels, \n",
    "                out_channels=input_channels//reduction, \n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.ReLU(True),\n",
    "            nn.Conv1d(\n",
    "                in_channels=input_channels//reduction, \n",
    "                out_channels=input_channels, \n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y_squeeze = self.squeeze(x)\n",
    "        y_excitation = self.excitation(y_squeeze)\n",
    "        y = x * y_excitation\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Res2NetConv(nn.Module):\n",
    "    def __init__(\n",
    "        self,         \n",
    "        hidden: int, \n",
    "        dilation: int, \n",
    "        scale: int,\n",
    "        kernel_size: int = 3\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        if hidden % scale != 0:\n",
    "            raise ValueError(\"hidden must be divisible by scale\")\n",
    "        \n",
    "        self.scale = scale\n",
    "        \n",
    "        conv2d_channels = hidden // scale\n",
    "        \n",
    "        self.convs2d = nn.ModuleList(\n",
    "            nn.Conv1d(\n",
    "                in_channels=conv2d_channels,\n",
    "                out_channels=conv2d_channels,\n",
    "                kernel_size=kernel_size,\n",
    "                dilation=dilation,\n",
    "                padding=dilation * (kernel_size - 1) // 2\n",
    "            ) for _ in range(scale - 1)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        assert x.shape[1] % self.scale == 0\n",
    "        \n",
    "        x_scales = torch.split(x, x.shape[1] // self.scale, dim=1)\n",
    "        \n",
    "        y_list = []\n",
    "        \n",
    "        for idx, x_curr in enumerate(x_scales):\n",
    "            if idx >= 2:\n",
    "                x_curr = x_curr + x_prev\n",
    "            if idx >= 1:\n",
    "                x_curr = self.convs2d[idx - 1](x_curr)\n",
    "            \n",
    "            y_list.append(x_curr)\n",
    "            x_prev = x_curr\n",
    "            \n",
    "        y = torch.cat(y_list, dim=1)\n",
    "        \n",
    "        return y\n",
    "\n",
    "\n",
    "class Res2Net(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        hidden: int, \n",
    "        dilation: int, \n",
    "        scale: int,\n",
    "        reduction: int = 4,\n",
    "        kernel_size: int = 3\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        # conv2d_channels = hidden // scale\n",
    "        if hidden % scale != 0:\n",
    "            raise ValueError(\"hidden must be divisible by scale\")\n",
    "        \n",
    "        self.scale = scale\n",
    "        \n",
    "        input_conv = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=hidden, \n",
    "                out_channels=hidden,\n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(num_features=hidden)\n",
    "        )\n",
    "        \n",
    "        res2netconv = Res2NetConv(\n",
    "            hidden=hidden,\n",
    "            dilation=dilation,\n",
    "            scale=scale,\n",
    "            kernel_size=kernel_size\n",
    "        )\n",
    "        \n",
    "        output_conv = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=hidden,\n",
    "                out_channels=hidden,\n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(num_features=hidden)\n",
    "        )\n",
    "        \n",
    "        se_block = SEBlock(\n",
    "            input_channels=hidden,\n",
    "            reduction=reduction\n",
    "        )\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            input_conv,\n",
    "            res2netconv,\n",
    "            output_conv,\n",
    "            se_block\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        return self.model(x) + x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcapaBlock(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_channels: int,\n",
    "        hidden: int, \n",
    "        scale: int = 8\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        if hidden % scale != 0:\n",
    "            raise ValueError(\"hidden must be divisible by scale\")\n",
    "        \n",
    "        self.input_conv = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=input_channels,\n",
    "                out_channels=hidden,\n",
    "                kernel_size=5\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.BatchNorm1d(num_features=hidden)\n",
    "        )\n",
    "        \n",
    "        # bottleneck_dim = hidden // reduction\n",
    "        self.res2net_1 = Res2Net(\n",
    "            hidden=hidden,\n",
    "            dilation=2,\n",
    "            scale=scale,\n",
    "            reduction=4,\n",
    "            kernel_size=3\n",
    "        )\n",
    "        \n",
    "        self.res2net_2 = Res2Net(\n",
    "            hidden=hidden,\n",
    "            dilation=3,\n",
    "            scale=scale,\n",
    "            reduction=4,\n",
    "            kernel_size=3\n",
    "        )\n",
    "        \n",
    "        self.res2net_3 = Res2Net(\n",
    "            hidden=hidden,\n",
    "            dilation=4,\n",
    "            scale=scale,\n",
    "            reduction=4,\n",
    "            kernel_size=3\n",
    "        )\n",
    "        \n",
    "        self.output_conv = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=3*hidden,\n",
    "                out_channels=1536,\n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        y0 = self.input_conv(x)\n",
    "        \n",
    "        y1 = self.res2net_1(y0)\n",
    "        y2 = self.res2net_2(y1)\n",
    "        y3 = self.res2net_3(y2)\n",
    "        \n",
    "        y = self.output_conv(torch.cat((y1, y2, y3), dim=1))\n",
    "        \n",
    "        return y        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AttentiveStatsPooling(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_channels: int, \n",
    "        bottleneck_channels: int = 128\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.attention = nn.Sequential(\n",
    "            nn.Conv1d(\n",
    "                in_channels=3*input_channels,\n",
    "                out_channels=bottleneck_channels,\n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv1d(\n",
    "                in_channels=bottleneck_channels,\n",
    "                out_channels=input_channels,\n",
    "                kernel_size=1\n",
    "            ),\n",
    "            nn.Softmax(dim=2)  # along the last (time dim)\n",
    "        )\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, C, T = x.shape\n",
    "        \n",
    "        time_mean = torch.mean(x, dim=2, keepdim=True).expand(B, C, T)  # (B, C, 1) -> (B, C, T)\n",
    "        time_std = torch.std(x, dim=2, keepdim=True).expand(B, C, T)  # (B, C, 1) -> (B, C, T)\n",
    "        \n",
    "        h = torch.cat((x, time_mean, time_std), dim=1)  # (B, 3C, T)\n",
    "        \n",
    "        alpha = self.attention(h)  # (B, C, T)\n",
    "        \n",
    "        weighted_mean = torch.sum(alpha * x, dim=2)  # (B, C)\n",
    "        weighted_var = torch.sum(alpha * x**2, dim=2) - weighted_mean**2  # (B, C)\n",
    "        weighted_std = torch.sqrt(torch.clamp_min(weighted_var, min=1e-9))  # (B, C)\n",
    "        \n",
    "        y = torch.cat((weighted_mean, weighted_std), dim=1)  # (B, C)\n",
    "        \n",
    "        return y   # (B, C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AAMSoftmax(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_channels: int, \n",
    "        n_classes: int, \n",
    "        margin: float = 0.2, \n",
    "        scale: float = 30.\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        self.n_classes = n_classes\n",
    "        self.margin = margin\n",
    "        self.scale = scale \n",
    "        \n",
    "        self.weights = nn.Parameter(torch.zeros((n_classes, input_channels), dtype=torch.float32))\n",
    "        nn.init.xavier_uniform_(self.weights)\n",
    "        \n",
    "        self._cos_m = math.cos(self.margin)\n",
    "        self._sin_m = math.sin(self.margin) \n",
    "        \n",
    "        # cos(theta + m) > cos(theta) on [0; pi] if theta + m > pi\n",
    "        self._cos_thres = math.cos(math.pi - self.margin)\n",
    "        # linear approx. in the vicinity of (pi - margin) to preserve monotonically decreasing property \n",
    "        self._cos_m_thres_dec = math.sin(math.pi - self.margin) * self.margin\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        B, ch = x.shape\n",
    "        \n",
    "        x_norm = F.normalize(x, p=2, dim=1)  # (B, ch)\n",
    "        weights_norm = F.normalize(self.weights, p=2, dim=1)  # (n_classes, ch)\n",
    "        \n",
    "        cos_theta = F.linear(x_norm, weights_norm).clamp(-1.0, 1.0)  # (B, n_classes)\n",
    "        exp_s_cos_theta = torch.exp(self.scale * cos_theta)  # (B, n_classes)\n",
    "        \n",
    "        sin_theta = torch.sqrt(torch.clamp_min(1 - cos_theta**2, min=1e-9))  # (B, n_classes)\n",
    "        \n",
    "        # cos(theta + m)\n",
    "        cos_theta_m = cos_theta * self._cos_m - sin_theta * self._sin_m  # (B, n_classes)\n",
    "        cos_theta_m = torch.where(cos_theta - self._cos_thres > 0, cos_theta_m, cos_theta - self._cos_m_thres_dec)\n",
    "        \n",
    "        exp_s_cos_theta_m = torch.exp(self.scale * cos_theta_m)\n",
    "        \n",
    "        Z = torch.sum(exp_s_cos_theta, dim=1, keepdim=True) - exp_s_cos_theta + exp_s_cos_theta_m\n",
    "        \n",
    "        S = self.scale * cos_theta_m - torch.log(Z)\n",
    "        \n",
    "        return S  # (B, n_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EcapaTDNN(nn.Module):\n",
    "    def __init__(\n",
    "        self, \n",
    "        input_channels: int, \n",
    "        n_classes: int,\n",
    "        hidden: int,\n",
    "        bottleneck_channels: int = 128,\n",
    "        embedding_dim: int = 192,\n",
    "        ecapa_scale: int = 8,\n",
    "    ) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "        ecapa_block = EcapaBlock(\n",
    "            input_channels=input_channels,\n",
    "            hidden=hidden,\n",
    "            scale=ecapa_scale\n",
    "        )\n",
    "        \n",
    "        attentive_stat_pooling = AttentiveStatsPooling(\n",
    "            input_channels=1536,\n",
    "            bottleneck_channels=bottleneck_channels\n",
    "        )\n",
    "        \n",
    "        self.emb_model = nn.Sequential(\n",
    "            ecapa_block,\n",
    "            attentive_stat_pooling,\n",
    "            nn.BatchNorm1d(num_features=1536*2),\n",
    "            nn.Linear(\n",
    "                in_features=1536*2,\n",
    "                out_features=embedding_dim\n",
    "            ),\n",
    "            nn.BatchNorm1d(num_features=embedding_dim)\n",
    "        )\n",
    "        \n",
    "        self.head = AAMSoftmax(\n",
    "            input_channels=embedding_dim,\n",
    "            n_classes=n_classes,            \n",
    "        )\n",
    "        \n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> tuple[torch.Tensor, torch.Tensor]:\n",
    "        emb = self.emb_model(x)\n",
    "        outp = self.head(emb)\n",
    "        \n",
    "        return outp, emb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train ECAPA model, at this point you can archive stable score (for several consecutive epochs) near 0.08 EER.\n",
    "\n",
    "You can train ECAPA with hidden size 256 to increase speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "ecapatdnn = EcapaTDNN(FEATS, trainset.speakers(), 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6188416"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pn = 0\n",
    "for p in ecapatdnn.emb_model.parameters():\n",
    "    pn += p.numel()\n",
    "pn  # parameters without head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x = torch.randn(8, 80, 500)\n",
    "# ecapatdnn = EcapaTDNN(FEATS, trainset.speakers(), 512)\n",
    "\n",
    "# from torchview import draw_graph\n",
    "\n",
    "# model_graph = draw_graph(\n",
    "#     ecapatdnn, \n",
    "#     input_size=x.shape, \n",
    "#     expand_nested=True, \n",
    "#     depth=3,\n",
    "#     graph_dir='TB',\n",
    "# )\n",
    "# model_graph.visual_graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a0eec91877448ee9587ee5ea736d675",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2119 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[115], line 8\u001b[0m\n\u001b[0;32m      6\u001b[0m opt \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters())\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m# train(model, opt, batch_size=128)\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[105], line 13\u001b[0m, in \u001b[0;36mtrain\u001b[1;34m(model, opt, batch_size, epochs, train_fun, train_kwargs)\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m     12\u001b[0m     model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m---> 13\u001b[0m     train_losses\u001b[38;5;241m.\u001b[39mappend(\u001b[43mtrain_fun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m     14\u001b[0m     model\u001b[38;5;241m.\u001b[39meval()\n\u001b[0;32m     15\u001b[0m     eval_scores\u001b[38;5;241m.\u001b[39mappend(calc_eval_score(model, batch_size\u001b[38;5;241m=\u001b[39mbatch_size))\n",
      "Cell \u001b[1;32mIn[102], line 13\u001b[0m, in \u001b[0;36mtrain_stage\u001b[1;34m(model, opt, batch_size)\u001b[0m\n\u001b[0;32m     11\u001b[0m batches \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m X, Y, _ \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(loader):\n\u001b[1;32m---> 13\u001b[0m     logits, _ \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDEVICE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m     loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mnll_loss(logits, Y\u001b[38;5;241m.\u001b[39mto(DEVICE))\n\u001b[0;32m     15\u001b[0m     loss_sum \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n",
      "Cell \u001b[1;32mIn[112], line 42\u001b[0m, in \u001b[0;36mEcapaTDNN.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[torch\u001b[38;5;241m.\u001b[39mTensor, torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m---> 42\u001b[0m     emb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43memb_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     43\u001b[0m     outp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead(emb)\n\u001b[0;32m     45\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outp, emb\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[108], line 61\u001b[0m, in \u001b[0;36mEcapaBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     58\u001b[0m y0 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_conv(x)\n\u001b[0;32m     60\u001b[0m y1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres2net_1(y0)\n\u001b[1;32m---> 61\u001b[0m y2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mres2net_2\u001b[49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     62\u001b[0m y3 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mres2net_3(y2)\n\u001b[0;32m     64\u001b[0m y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput_conv(torch\u001b[38;5;241m.\u001b[39mcat((y1, y2, y3), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[107], line 106\u001b[0m, in \u001b[0;36mRes2Net.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 106\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m+\u001b[39m x\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[107], line 39\u001b[0m, in \u001b[0;36mRes2NetConv.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     37\u001b[0m     x_curr \u001b[38;5;241m=\u001b[39m x_curr \u001b[38;5;241m+\u001b[39m x_prev\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m idx \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m---> 39\u001b[0m     x_curr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs2d\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_curr\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m y_list\u001b[38;5;241m.\u001b[39mappend(x_curr)\n\u001b[0;32m     42\u001b[0m x_prev \u001b[38;5;241m=\u001b[39m x_curr\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1734\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1735\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1736\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1742\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1743\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1744\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1745\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1746\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1747\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1749\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1750\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:375\u001b[0m, in \u001b[0;36mConv1d.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 375\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_conv_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\nazmievairat\\anaconda3\\envs\\python312\\Lib\\site-packages\\torch\\nn\\modules\\conv.py:370\u001b[0m, in \u001b[0;36mConv1d._conv_forward\u001b[1;34m(self, input, weight, bias)\u001b[0m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mzeros\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mconv1d(\n\u001b[0;32m    360\u001b[0m         F\u001b[38;5;241m.\u001b[39mpad(\n\u001b[0;32m    361\u001b[0m             \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_mode\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgroups,\n\u001b[0;32m    369\u001b[0m     )\n\u001b[1;32m--> 370\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconv1d\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    371\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbias\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdilation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroups\u001b[49m\n\u001b[0;32m    372\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = EcapaTDNN(\n",
    "    input_channels=FEATS, \n",
    "    n_classes=trainset.speakers(), \n",
    "    hidden=512\n",
    ").to(DEVICE)\n",
    "opt = optim.Adam(model.parameters())\n",
    "# train(model, opt, batch_size=128)\n",
    "train(model, opt, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model to preserve results before uptraining experiments\n",
    "torch.save(model, 'model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contrastive losses (10 points)\n",
    "\n",
    "You can use anyone constrative loss.\n",
    "Good article with contrastive losses https://lilianweng.github.io/posts/2021-05-31-contrastive/\n",
    "\n",
    "Base losses:\n",
    "- contrastive\n",
    "- triplet -- it gives a better quality usually\n",
    "- lifted structured loss -- better batch data utilization\n",
    "\n",
    "The main problem with contrastive loss is the positive pairs sampler.\n",
    "This is because a large number of classes provided only once per batch\n",
    "in case of large number of classes in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositivePairsSampler(torch.utils.data.Sampler):\n",
    "    def __init__(self, speakers: list[int], batch_size: int):\n",
    "        pass\n",
    "        # <YOUR CODE IS HERE>\n",
    "\n",
    "    def __len__(self):\n",
    "        pass\n",
    "        # <YOUR CODE IS HERE>\n",
    "\n",
    "    def __iter__(self):\n",
    "        # yield __len__ batches as list of indexes of samples from dataset\n",
    "        # <YOUR CODE IS HERE>\n",
    "        for _ in range(len(self)):\n",
    "            indexes = []\n",
    "            # <YOUR CODE IS HERE>\n",
    "            yield indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def contrastive_train_stage(model, opt, batch_size: int = 256):\n",
    "    # You can use any contrastive loss here to improve training\n",
    "    # You can combine contrastive loss with the NLL loss after AAM softmax to improve stability\n",
    "    loader = torch_data.DataLoader(\n",
    "        trainset,\n",
    "        collate_fn=dataset.collate_fn,\n",
    "        num_workers=LOADER_WORKERS,\n",
    "        batch_sampler=PositivePairsSampler(trainset._speakers, batch_size)\n",
    "    )\n",
    "    # <YOUR CODE IS HERE>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train model with contrastive loss here. At this point you can archive EER near 0.06-0.07 (it should be at least on 0.005 to 0.01 better than before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load('model.pt').to(DEVICE)\n",
    "opt = optim.Adam(model.parameters())\n",
    "train(model, opt, batch_size=128, train_fun=contrastive_train_stage)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
